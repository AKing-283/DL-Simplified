{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing of GoodReads_100K\n",
    "* If you want to process GoodReads_100K.csv: https://www.kaggle.com/datasets/mdhamani/goodreads-books-100k/\n",
    "* Run this code to make final_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset into a Pandas DataFrame\n",
    "data = pd.read_csv(\"dataset\\GoodReads_100k.csv\")\n",
    "data.size\n",
    "\n",
    "# Remove duplicates from df\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Handle outliers (e.g., filter unrealistic ratings)\n",
    "data = data[(data['rating'] >= 1) & (data['rating'] <= 10)]\n",
    "\n",
    "# Remove columns that are not needed\n",
    "data = data[['isbn','title','author','rating','reviews','img','desc','genre','pages']]\n",
    "\n",
    "# Rename columns\n",
    "data.rename(columns={'isbn':'ISBN','title':'Title','link':'Link','author':'Author','rating':'Rating','reviews':'No. of ratings','img':'Image','desc':'Desc','genre':'Genre','pages':'Pages'},inplace=True)\n",
    "\n",
    "data.isnull().sum() # no. of null values\n",
    "data = data.dropna(subset=['Genre'])\n",
    "data = data.dropna(subset=['Desc'])\n",
    "data = data.dropna(subset=['Image'])\n",
    "data = data.dropna(subset=['ISBN'])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Filter out books with greater than 50 ratings\n",
    "final_data = data[data['No. of ratings'] >= 50]\n",
    "final_data = final_data.reset_index(drop=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "final_data.to_csv('dataset\\\\final_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run this code to make `final_data_with_ratings.csv` file from `final_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the Goodreads dataset\n",
    "final_data = pd.read_csv('final_data.csv')\n",
    "\n",
    "# Simulate user-book ratings\n",
    "# Assume 1000 users and assign random ratings between 1 and 5 to each book by users\n",
    "num_users = 1000\n",
    "num_ratings = len(final_data)\n",
    "\n",
    "# Generate random user IDs\n",
    "user_ids = np.random.randint(1, num_users + 1, num_ratings)\n",
    "\n",
    "# Generate random ratings\n",
    "ratings = np.random.randint(1, 6, num_ratings)\n",
    "\n",
    "# Add user IDs and ratings to the dataset\n",
    "final_data['user_id'] = user_ids\n",
    "final_data['rating'] = ratings\n",
    "\n",
    "# Prepare the data for NCF\n",
    "# Encode the user IDs and ISBNs\n",
    "final_data['user_id'] = final_data['user_id'].astype(\n",
    "    'category').cat.codes.values\n",
    "final_data['ISBN'] = final_data['ISBN'].astype('category').cat.codes.values\n",
    "\n",
    "\n",
    "# Save the final_data to a CSV file\n",
    "final_data.to_csv(\"model/final_data_with_ratings.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
